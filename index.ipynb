{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Our Data - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this lab we'll perform a full linear regression on our data. We'll take a stepwise approach and we'll try to improve our model as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "\n",
    "* Remove predictors with p-values too high and refit the model\n",
    "* Examine and interpret the model results\n",
    "* Split data into training and testing sets\n",
    "* Fit a regression model to the data set using statsmodel library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build single linear regression models\n",
    "\n",
    "From the previous steps, it is pretty clear that we have quite a few predictors, but there are some issues with them. Linearity with the target \"Weekly_Sales\" wasn't apparent. If that's the case, it's always smart to start small, and go ahead and build linear regression models with just one input at the time. Somewhat like what we've done in section 10, let's look at some statistics for single linear regression models for all our *continuous* variables with the outcome.\n",
    "\n",
    "**Note: for now, we will not use holdout validation, as we're just trying to gauge interpretation and a sense of predictive capacity for each of the candidate predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cleaned dataset \"walmart_dataset.csv\", and check its contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Store_1</th>\n",
       "      <th>Store_10</th>\n",
       "      <th>Store_2</th>\n",
       "      <th>...</th>\n",
       "      <th>binned_markdown_4_41-60%</th>\n",
       "      <th>binned_markdown_4_61-80%</th>\n",
       "      <th>binned_markdown_4_81-100%</th>\n",
       "      <th>binned_markdown_4_NaN</th>\n",
       "      <th>binned_markdown_5_0-20%</th>\n",
       "      <th>binned_markdown_5_21-40%</th>\n",
       "      <th>binned_markdown_5_41-60%</th>\n",
       "      <th>binned_markdown_5_61-80%</th>\n",
       "      <th>binned_markdown_5_81-100%</th>\n",
       "      <th>binned_markdown_5_NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50605.27</td>\n",
       "      <td>False</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13740.12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39954.04</td>\n",
       "      <td>False</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32229.38</td>\n",
       "      <td>False</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weekly_Sales  IsHoliday      Size  Temperature  Fuel_Price      CPI  \\\n",
       "0      24924.50      False  0.283436    -1.301205    -1.56024  0.40349   \n",
       "1      50605.27      False  0.283436    -1.301205    -1.56024  0.40349   \n",
       "2      13740.12      False  0.283436    -1.301205    -1.56024  0.40349   \n",
       "3      39954.04      False  0.283436    -1.301205    -1.56024  0.40349   \n",
       "4      32229.38      False  0.283436    -1.301205    -1.56024  0.40349   \n",
       "\n",
       "   Unemployment  Store_1  Store_10  Store_2          ...            \\\n",
       "0      0.913194        1         0        0          ...             \n",
       "1      0.913194        1         0        0          ...             \n",
       "2      0.913194        1         0        0          ...             \n",
       "3      0.913194        1         0        0          ...             \n",
       "4      0.913194        1         0        0          ...             \n",
       "\n",
       "   binned_markdown_4_41-60%  binned_markdown_4_61-80%  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   binned_markdown_4_81-100%  binned_markdown_4_NaN  binned_markdown_5_0-20%  \\\n",
       "0                          0                      1                        0   \n",
       "1                          0                      1                        0   \n",
       "2                          0                      1                        0   \n",
       "3                          0                      1                        0   \n",
       "4                          0                      1                        0   \n",
       "\n",
       "   binned_markdown_5_21-40%  binned_markdown_5_41-60%  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   binned_markdown_5_61-80%  binned_markdown_5_81-100%  binned_markdown_5_NaN  \n",
       "0                         0                          0                      1  \n",
       "1                         0                          0                      1  \n",
       "2                         0                          0                      1  \n",
       "3                         0                          0                      1  \n",
       "4                         0                          0                      1  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('walmart_dataset_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull up the info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Columns: 127 entries, Weekly_Sales to binned_markdown_5_NaN\n",
      "dtypes: bool(1), float64(6), int64(120)\n",
      "memory usage: 94.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output for info is much smaller compared to what we usually see. Because we have so many columns, pandas is intentionally not showing the data types for each column. Let's use `info()` again, but now just on the first 15 columns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Data columns (total 15 columns):\n",
      "Weekly_Sales    97839 non-null float64\n",
      "IsHoliday       97839 non-null bool\n",
      "Size            97839 non-null float64\n",
      "Temperature     97839 non-null float64\n",
      "Fuel_Price      97839 non-null float64\n",
      "CPI             97839 non-null float64\n",
      "Unemployment    97839 non-null float64\n",
      "Store_1         97839 non-null int64\n",
      "Store_10        97839 non-null int64\n",
      "Store_2         97839 non-null int64\n",
      "Store_3         97839 non-null int64\n",
      "Store_4         97839 non-null int64\n",
      "Store_5         97839 non-null int64\n",
      "Store_6         97839 non-null int64\n",
      "Store_7         97839 non-null int64\n",
      "dtypes: bool(1), float64(6), int64(8)\n",
      "memory usage: 10.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.iloc[:,:15].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that all the columns from store_1 onwards are actually dummies, so categorical variables. Because we stored the data and loaded it in again, this information was lost. Let's make sure they become categorical again. You can write a for-loop to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,col in enumerate(df.columns):\n",
    "    if i > 6:\n",
    "        df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure IsHoliday is a categorical variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsHoliday'] = df['IsHoliday'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the info again to make sure everything is OK now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Data columns (total 15 columns):\n",
      "Weekly_Sales    97839 non-null float64\n",
      "IsHoliday       97839 non-null category\n",
      "Size            97839 non-null float64\n",
      "Temperature     97839 non-null float64\n",
      "Fuel_Price      97839 non-null float64\n",
      "CPI             97839 non-null float64\n",
      "Unemployment    97839 non-null float64\n",
      "Store_1         97839 non-null category\n",
      "Store_10        97839 non-null category\n",
      "Store_2         97839 non-null category\n",
      "Store_3         97839 non-null category\n",
      "Store_4         97839 non-null category\n",
      "Store_5         97839 non-null category\n",
      "Store_6         97839 non-null category\n",
      "Store_7         97839 non-null category\n",
      "dtypes: category(9), float64(6)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.iloc[:,:15].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! you should see that the datatypes have changed to categories now! If you use `.describe` now, you should see only the remaining continuous variables in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97839.000000</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17223.235591</td>\n",
       "      <td>-8.044340e-14</td>\n",
       "      <td>2.339480e-13</td>\n",
       "      <td>4.784098e-13</td>\n",
       "      <td>-9.181116e-15</td>\n",
       "      <td>1.795967e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25288.572553</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1098.000000</td>\n",
       "      <td>-1.611999e+00</td>\n",
       "      <td>-3.843452e+00</td>\n",
       "      <td>-1.691961e+00</td>\n",
       "      <td>-1.958762e+00</td>\n",
       "      <td>-2.776898e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2336.485000</td>\n",
       "      <td>-1.028620e+00</td>\n",
       "      <td>-7.087592e-01</td>\n",
       "      <td>-1.053793e+00</td>\n",
       "      <td>-1.266966e-01</td>\n",
       "      <td>-6.503157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7658.280000</td>\n",
       "      <td>2.834360e-01</td>\n",
       "      <td>1.340726e-01</td>\n",
       "      <td>1.180741e-01</td>\n",
       "      <td>4.995210e-01</td>\n",
       "      <td>-4.621274e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20851.275000</td>\n",
       "      <td>1.113495e+00</td>\n",
       "      <td>8.680410e-01</td>\n",
       "      <td>8.243739e-01</td>\n",
       "      <td>6.346144e-01</td>\n",
       "      <td>7.089160e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>693099.360000</td>\n",
       "      <td>1.171380e+00</td>\n",
       "      <td>1.738375e+00</td>\n",
       "      <td>2.745691e+00</td>\n",
       "      <td>8.517705e-01</td>\n",
       "      <td>2.361469e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Weekly_Sales          Size   Temperature    Fuel_Price           CPI  \\\n",
       "count   97839.000000  9.783900e+04  9.783900e+04  9.783900e+04  9.783900e+04   \n",
       "mean    17223.235591 -8.044340e-14  2.339480e-13  4.784098e-13 -9.181116e-15   \n",
       "std     25288.572553  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min     -1098.000000 -1.611999e+00 -3.843452e+00 -1.691961e+00 -1.958762e+00   \n",
       "25%      2336.485000 -1.028620e+00 -7.087592e-01 -1.053793e+00 -1.266966e-01   \n",
       "50%      7658.280000  2.834360e-01  1.340726e-01  1.180741e-01  4.995210e-01   \n",
       "75%     20851.275000  1.113495e+00  8.680410e-01  8.243739e-01  6.346144e-01   \n",
       "max    693099.360000  1.171380e+00  1.738375e+00  2.745691e+00  8.517705e-01   \n",
       "\n",
       "       Unemployment  \n",
       "count  9.783900e+04  \n",
       "mean   1.795967e-12  \n",
       "std    1.000000e+00  \n",
       "min   -2.776898e+00  \n",
       "25%   -6.503157e-01  \n",
       "50%   -4.621274e-02  \n",
       "75%    7.089160e-01  \n",
       "max    2.361469e+00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a for-loop to look at some results for each linear regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use ordinary least squares in statsmodels at this stage.\n",
    "Import `statsmodels.formula.api` to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a loop that for each iteration:\n",
    "* Runs a simple OLS regression between (continuous) independent and dependent variables\n",
    "* Store following values in array for each iteration\n",
    "    * Target variable\n",
    "    * R_squared\n",
    "    * intercept\n",
    "    * slope\n",
    "    * p-value\n",
    "* Comment on each output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size\n",
      "----------\n",
      "['Size', 0.08577198301194777, 17223.235590817574, 7406.227377929049, 0.0]\n",
      "Temperature\n",
      "----------\n",
      "['Temperature', 0.0010145286600620196, 17223.235590817378, 805.4831797033963, 2.160985815462691e-23]\n",
      "Fuel_Price\n",
      "----------\n",
      "['Fuel_Price', 0.0008029403665875678, 17223.235590817232, 716.5821103232543, 7.649612001141253e-19]\n",
      "CPI\n",
      "----------\n",
      "['CPI', 0.039410515354355025, 17223.2355908175, -5020.308120380831, 0.0]\n",
      "Unemployment\n",
      "----------\n",
      "['Unemployment', 0.0008517114683159743, 17223.235590816246, 738.0241329746427, 6.825456986258902e-20]\n"
     ]
    }
   ],
   "source": [
    "var = ['Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "results = [['ind', 'rsquared', 'intercept', 'slope', 'pval']]\n",
    "\n",
    "for i, col in enumerate(var):\n",
    "    print(col)\n",
    "    print('----------')\n",
    "    f = \"Weekly_Sales~\" + col\n",
    "    model = smf.ols(f, df).fit()\n",
    "    r = [col, model.rsquared, model.params[0], model.params[1], model.pvalues[1]]\n",
    "    results.append(r)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ind</td>\n",
       "      <td>rsquared</td>\n",
       "      <td>intercept</td>\n",
       "      <td>slope</td>\n",
       "      <td>pval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>0.085772</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>7406.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>0.00101453</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>805.483</td>\n",
       "      <td>2.16099e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuel_Price</td>\n",
       "      <td>0.00080294</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>716.582</td>\n",
       "      <td>7.64961e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.0394105</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>-5020.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>0.000851711</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>738.024</td>\n",
       "      <td>6.82546e-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1          2        3            4\n",
       "0           ind     rsquared  intercept    slope         pval\n",
       "1          Size     0.085772    17223.2  7406.23            0\n",
       "2   Temperature   0.00101453    17223.2  805.483  2.16099e-23\n",
       "3    Fuel_Price   0.00080294    17223.2  716.582  7.64961e-19\n",
       "4           CPI    0.0394105    17223.2 -5020.31            0\n",
       "5  Unemployment  0.000851711    17223.2  738.024  6.82546e-20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearreg= pd.DataFrame(results)\n",
    "linearreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about your results. \n",
    "- What do the parameter estimates mean? Do they make sense? \n",
    "- What do the p-values tell us?\n",
    "- What does the R-squared tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our R-squared values are low, let's try to solve this\n",
    "\n",
    "Something we haven't considered before, is taking log-transformations to make certain data less skewed. Let's take a quick look at our summarizing histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(8,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the most problematic variable in terms of skewness seems to be weekly sales itself. Does it make sense to log-transform this variable? It definitely doesn't hurt to try! Let's have a look below. what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "range parameter must be finite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-62a10d9db3e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeekly_Sales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mhist_series\u001b[0;34m(self, by, ax, grid, xlabelsize, xrot, ylabelsize, yrot, figsize, bins, **kwds)\u001b[0m\n\u001b[1;32m   2479\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2482\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m         \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   6528\u001b[0m             \u001b[0;31m# this will automatically overwrite bins,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6529\u001b[0m             \u001b[0;31m# so that each histogram uses the same bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6530\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6531\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# causes problems later if it's an int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmlast\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         raise ValueError(\n\u001b[0;32m--> 670\u001b[0;31m             'range parameter must be finite.')\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst_edge\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mfirst_edge\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: range parameter must be finite."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df.Weekly_Sales).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    9.763100e+04\n",
       "mean             -inf\n",
       "std               NaN\n",
       "min              -inf\n",
       "25%      7.765571e+00\n",
       "50%      8.948268e+00\n",
       "75%      9.947998e+00\n",
       "max      1.344893e+01\n",
       "Name: Weekly_Sales, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(df.Weekly_Sales).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, we have some negative `Weekly_Sales` values! Let's check how many we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.Weekly_Sales<=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems negligibe considering we have almost 100,000 observations. Let's remove these 224 rows so we can take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Weekly_Sales>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have another look at the histogram. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10f454390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df.Weekly_Sales).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's repeat what we did before, yet now with the log(Weekly_Sales) as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['Log_Sales'] = np.log(df.Weekly_Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size\n",
      "----------\n",
      "['Size', 0.10780975018477779, 8.671485180985368, 0.6116185906202127, 0.0]\n",
      "Temperature\n",
      "----------\n",
      "['Temperature', 0.0007654996204087272, 8.671603611690758, 0.0515690944972903, 5.3400172912048595e-18]\n",
      "Fuel_Price\n",
      "----------\n",
      "['Fuel_Price', 0.00044928127033871945, 8.671613962769431, 0.03949232656972057, 3.5176641775608455e-11]\n",
      "CPI\n",
      "----------\n",
      "['CPI', 0.025949085295407515, 8.671703573822903, -0.3002071974538499, 0.0]\n",
      "Unemployment\n",
      "----------\n",
      "['Unemployment', 0.00027696050787828774, 8.671620744194504, 0.03101368076921429, 1.9943786070646916e-07]\n"
     ]
    }
   ],
   "source": [
    "var = ['Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "results = [['ind', 'rsquared', 'intercept', 'slope', 'pval']]\n",
    "\n",
    "for i, col in enumerate(var):\n",
    "    print(col)\n",
    "    print('----------')\n",
    "    f = \"Log_Sales~\" + col\n",
    "    model = smf.ols(f, df).fit()\n",
    "    r = [col, model.rsquared, model.params[0], model.params[1], model.pvalues[1]]\n",
    "    results.append(r)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ind</td>\n",
       "      <td>rsquared</td>\n",
       "      <td>intercept</td>\n",
       "      <td>slope</td>\n",
       "      <td>pval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>0.10781</td>\n",
       "      <td>8.67149</td>\n",
       "      <td>0.611619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>0.0007655</td>\n",
       "      <td>8.6716</td>\n",
       "      <td>0.0515691</td>\n",
       "      <td>5.34002e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuel_Price</td>\n",
       "      <td>0.000449281</td>\n",
       "      <td>8.67161</td>\n",
       "      <td>0.0394923</td>\n",
       "      <td>3.51766e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.0259491</td>\n",
       "      <td>8.6717</td>\n",
       "      <td>-0.300207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>0.000276961</td>\n",
       "      <td>8.67162</td>\n",
       "      <td>0.0310137</td>\n",
       "      <td>1.99438e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1          2          3            4\n",
       "0           ind     rsquared  intercept      slope         pval\n",
       "1          Size      0.10781    8.67149   0.611619            0\n",
       "2   Temperature    0.0007655     8.6716  0.0515691  5.34002e-18\n",
       "3    Fuel_Price  0.000449281    8.67161  0.0394923  3.51766e-11\n",
       "4           CPI    0.0259491     8.6717  -0.300207            0\n",
       "5  Unemployment  0.000276961    8.67162  0.0310137  1.99438e-07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare and contract the results with the results obtained when we did not take the log(sales)\n",
    "- Which one would you want to proceed with based on this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with each categorical variable as a predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use it on the log-transformed, and the regular `Weekly_Sales`\n",
    "- put all categories for one categorical variable in 1 model, so we want 4 models.\n",
    "- remember that we have 4 categorical variables: `Store`,  `Dept`, `IsHoliday` and `Type`( we're for now ignoring the `binned_markdown` categories, you can add then later on as an extension)\n",
    "- IMPORTANT: remember that we made dummies for `Type`, `Dept` and `Store` columns. You'll need to drop 1 column for each of these if you want good results. The reason for this is that singularity will occur and . This is related to what we mentioned earlier on in section 11. Don't worry about the \"why\" for now, just make sure to drop 1 column and you should be fine! The parameter value for the dropper \"base category\" will be absorbed in the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dept_1', 'Dept_10', 'Dept_11', 'Dept_12', 'Dept_13', 'Dept_14',\n",
       "       'Dept_16', 'Dept_17', 'Dept_18', 'Dept_19', 'Dept_2', 'Dept_20',\n",
       "       'Dept_21', 'Dept_22', 'Dept_23', 'Dept_24', 'Dept_25', 'Dept_26',\n",
       "       'Dept_27', 'Dept_28', 'Dept_29', 'Dept_3', 'Dept_30', 'Dept_31',\n",
       "       'Dept_32', 'Dept_33', 'Dept_34', 'Dept_35', 'Dept_36', 'Dept_37',\n",
       "       'Dept_38', 'Dept_39', 'Dept_4', 'Dept_40', 'Dept_41', 'Dept_42',\n",
       "       'Dept_44', 'Dept_45', 'Dept_46', 'Dept_47', 'Dept_48', 'Dept_49',\n",
       "       'Dept_5', 'Dept_50', 'Dept_51', 'Dept_52', 'Dept_54', 'Dept_55',\n",
       "       'Dept_56', 'Dept_58', 'Dept_59', 'Dept_6', 'Dept_60', 'Dept_67',\n",
       "       'Dept_7', 'Dept_71', 'Dept_72', 'Dept_74', 'Dept_77', 'Dept_78',\n",
       "       'Dept_79', 'Dept_8', 'Dept_80', 'Dept_81', 'Dept_82', 'Dept_83',\n",
       "       'Dept_85', 'Dept_87', 'Dept_9', 'Dept_90', 'Dept_91', 'Dept_92',\n",
       "       'Dept_93', 'Dept_94', 'Dept_95', 'Dept_96', 'Dept_97', 'Dept_98'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[17:95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.123\n",
      "Method:                 Least Squares   F-statistic:                     1522.\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:03   Log-Likelihood:            -1.1218e+06\n",
      "No. Observations:               97615   AIC:                         2.244e+06\n",
      "Df Residuals:                   97605   BIC:                         2.244e+06\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     2.647e+04    233.948    113.162      0.000     2.6e+04    2.69e+04\n",
      "Store_1[T.1] -4724.9388    331.127    -14.269      0.000   -5373.945   -4075.933\n",
      "Store_2[T.1]   487.6497    331.225      1.472      0.141    -161.547    1136.847\n",
      "Store_3[T.1] -2.009e+04    341.974    -58.758      0.000   -2.08e+04   -1.94e+04\n",
      "Store_4[T.1]  2701.4553    330.796      8.167      0.000    2053.099    3349.812\n",
      "Store_5[T.1] -2.141e+04    342.460    -62.515      0.000   -2.21e+04   -2.07e+04\n",
      "Store_6[T.1] -4513.2850    331.428    -13.618      0.000   -5162.881   -3863.689\n",
      "Store_7[T.1] -1.809e+04    335.257    -53.972      0.000   -1.88e+04   -1.74e+04\n",
      "Store_8[T.1] -1.333e+04    333.993    -39.896      0.000    -1.4e+04   -1.27e+04\n",
      "Store_9[T.1] -1.767e+04    343.945    -51.369      0.000   -1.83e+04    -1.7e+04\n",
      "==============================================================================\n",
      "Omnibus:                    71707.896   Durbin-Watson:                   1.298\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2569497.337\n",
      "Skew:                           3.157   Prob(JB):                         0.00\n",
      "Kurtosis:                      27.329   Cond. No.                         10.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.503\n",
      "Model:                            OLS   Adj. R-squared:                  0.502\n",
      "Method:                 Least Squares   F-statistic:                     1265.\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:04   Log-Likelihood:            -1.0941e+06\n",
      "No. Observations:               97615   AIC:                         2.188e+06\n",
      "Df Residuals:                   97536   BIC:                         2.189e+06\n",
      "Df Model:                          78                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept      431.3373   1281.474      0.337      0.736   -2080.337    2943.011\n",
      "Dept_1[T.1]    2.03e+04   1365.635     14.867      0.000    1.76e+04     2.3e+04\n",
      "Dept_10[T.1]  2.736e+04   1365.635     20.038      0.000    2.47e+04       3e+04\n",
      "Dept_11[T.1]  1.908e+04   1365.635     13.972      0.000    1.64e+04    2.18e+04\n",
      "Dept_12[T.1]  6222.9237   1365.635      4.557      0.000    3546.294    8899.553\n",
      "Dept_13[T.1]  3.356e+04   1365.635     24.571      0.000    3.09e+04    3.62e+04\n",
      "Dept_14[T.1]   1.63e+04   1365.635     11.939      0.000    1.36e+04     1.9e+04\n",
      "Dept_16[T.1]  1.845e+04   1365.635     13.509      0.000    1.58e+04    2.11e+04\n",
      "Dept_17[T.1]   1.01e+04   1365.635      7.399      0.000    7427.204    1.28e+04\n",
      "Dept_18[T.1]  8078.6273   1391.819      5.804      0.000    5350.679    1.08e+04\n",
      "Dept_19[T.1]  1567.4807   1377.479      1.138      0.255   -1132.363    4267.324\n",
      "Dept_2[T.1]   4.739e+04   1365.635     34.699      0.000    4.47e+04    5.01e+04\n",
      "Dept_20[T.1]  5163.6415   1365.635      3.781      0.000    2487.012    7840.271\n",
      "Dept_21[T.1]  5409.5299   1365.635      3.961      0.000    2732.900    8086.159\n",
      "Dept_22[T.1]  1.028e+04   1365.635      7.530      0.000    7606.360     1.3e+04\n",
      "Dept_23[T.1]  2.459e+04   1365.635     18.004      0.000    2.19e+04    2.73e+04\n",
      "Dept_24[T.1]  5673.4257   1365.635      4.154      0.000    2996.796    8350.055\n",
      "Dept_25[T.1]  9587.0648   1365.635      7.020      0.000    6910.435    1.23e+04\n",
      "Dept_26[T.1]  7329.7879   1365.635      5.367      0.000    4653.158       1e+04\n",
      "Dept_27[T.1]  1078.8302   1365.635      0.790      0.430   -1597.799    3755.460\n",
      "Dept_28[T.1]   102.4398   1365.635      0.075      0.940   -2574.190    2779.069\n",
      "Dept_29[T.1]  4854.2609   1365.635      3.555      0.000    2177.632    7530.890\n",
      "Dept_3[T.1]   1.306e+04   1365.635      9.567      0.000    1.04e+04    1.57e+04\n",
      "Dept_30[T.1]  3541.8062   1365.635      2.594      0.010     865.177    6218.436\n",
      "Dept_31[T.1]  2101.3652   1365.635      1.539      0.124    -575.264    4777.995\n",
      "Dept_32[T.1]  8473.0120   1365.692      6.204      0.000    5796.271    1.11e+04\n",
      "Dept_33[T.1]  5834.4194   1365.635      4.272      0.000    3157.790    8511.049\n",
      "Dept_34[T.1]  1.388e+04   1365.635     10.161      0.000    1.12e+04    1.66e+04\n",
      "Dept_35[T.1]  2497.4479   1365.692      1.829      0.067    -179.293    5174.189\n",
      "Dept_36[T.1]  1485.2765   1365.922      1.087      0.277   -1191.914    4162.467\n",
      "Dept_37[T.1]  3093.6909   1418.973      2.180      0.029     312.521    5874.861\n",
      "Dept_38[T.1]  7.396e+04   1365.635     54.155      0.000    7.13e+04    7.66e+04\n",
      "Dept_39[T.1]  -429.1533   8084.465     -0.053      0.958   -1.63e+04    1.54e+04\n",
      "Dept_4[T.1]   2.891e+04   1365.635     21.172      0.000    2.62e+04    3.16e+04\n",
      "Dept_40[T.1]  5.131e+04   1365.635     37.574      0.000    4.86e+04     5.4e+04\n",
      "Dept_41[T.1]  1876.8782   1365.635      1.374      0.169    -799.751    4553.508\n",
      "Dept_42[T.1]  6510.3975   1365.635      4.767      0.000    3833.768    9187.027\n",
      "Dept_44[T.1]  4394.7593   1365.635      3.218      0.001    1718.130    7071.389\n",
      "Dept_45[T.1]  -405.7365   1500.440     -0.270      0.787   -3346.580    2535.108\n",
      "Dept_46[T.1]  2.182e+04   1365.635     15.976      0.000    1.91e+04    2.45e+04\n",
      "Dept_47[T.1]  -279.2666   2183.009     -0.128      0.898   -4557.939    3999.406\n",
      "Dept_48[T.1]  1194.1965   1422.411      0.840      0.401   -1593.713    3982.106\n",
      "Dept_49[T.1]  8409.1463   1389.045      6.054      0.000    5686.635    1.11e+04\n",
      "Dept_5[T.1]   2.604e+04   1365.635     19.067      0.000    2.34e+04    2.87e+04\n",
      "Dept_50[T.1]  3826.3230   1967.237      1.945      0.052     -29.439    7682.085\n",
      "Dept_51[T.1]  -411.3551   1794.245     -0.229      0.819   -3928.054    3105.344\n",
      "Dept_52[T.1]  2169.2487   1365.635      1.588      0.112    -507.381    4845.878\n",
      "Dept_54[T.1]  -323.0563   1379.449     -0.234      0.815   -3026.761    2380.649\n",
      "Dept_55[T.1]  1.101e+04   1365.635      8.065      0.000    8337.206    1.37e+04\n",
      "Dept_56[T.1]  3655.7740   1365.807      2.677      0.007     978.809    6332.740\n",
      "Dept_58[T.1]  5190.5691   1393.310      3.725      0.000    2459.697    7921.441\n",
      "Dept_59[T.1]   452.4510   1374.251      0.329      0.742   -2241.065    3145.966\n",
      "Dept_6[T.1]   4913.2359   1365.750      3.597      0.000    2236.383    7590.089\n",
      "Dept_60[T.1]   -94.7878   1373.699     -0.069      0.945   -2787.223    2597.647\n",
      "Dept_67[T.1]  7061.2917   1365.635      5.171      0.000    4384.662    9737.921\n",
      "Dept_7[T.1]   2.661e+04   1365.635     19.488      0.000    2.39e+04    2.93e+04\n",
      "Dept_71[T.1]  3990.1072   1365.635      2.922      0.003    1313.478    6666.737\n",
      "Dept_72[T.1]  5.894e+04   1365.635     43.156      0.000    5.63e+04    6.16e+04\n",
      "Dept_74[T.1]  1.419e+04   1365.635     10.389      0.000    1.15e+04    1.69e+04\n",
      "Dept_77[T.1]   118.7381   3727.644      0.032      0.975   -7187.401    7424.877\n",
      "Dept_78[T.1]  -420.3445   2980.382     -0.141      0.888   -6261.858    5421.169\n",
      "Dept_79[T.1]  2.285e+04   1365.635     16.736      0.000    2.02e+04    2.55e+04\n",
      "Dept_8[T.1]   3.713e+04   1365.635     27.186      0.000    3.44e+04    3.98e+04\n",
      "Dept_80[T.1]  1.156e+04   1397.061      8.272      0.000    8817.676    1.43e+04\n",
      "Dept_81[T.1]   1.39e+04   1365.635     10.181      0.000    1.12e+04    1.66e+04\n",
      "Dept_82[T.1]   1.59e+04   1365.635     11.640      0.000    1.32e+04    1.86e+04\n",
      "Dept_83[T.1]  3588.4037   1400.384      2.562      0.010     843.667    6333.141\n",
      "Dept_85[T.1]  1845.4836   1365.635      1.351      0.177    -831.146    4522.113\n",
      "Dept_87[T.1]  2.023e+04   1365.635     14.817      0.000    1.76e+04    2.29e+04\n",
      "Dept_9[T.1]    2.77e+04   1365.635     20.281      0.000     2.5e+04    3.04e+04\n",
      "Dept_90[T.1]  3.938e+04   1365.635     28.833      0.000    3.67e+04    4.21e+04\n",
      "Dept_91[T.1]  3.095e+04   1365.635     22.662      0.000    2.83e+04    3.36e+04\n",
      "Dept_92[T.1]  7.213e+04   1365.635     52.816      0.000    6.95e+04    7.48e+04\n",
      "Dept_93[T.1]  3.973e+04   1399.930     28.383      0.000     3.7e+04    4.25e+04\n",
      "Dept_94[T.1]  3.412e+04   1388.212     24.577      0.000    3.14e+04    3.68e+04\n",
      "Dept_95[T.1]  7.317e+04   1365.635     53.576      0.000    7.05e+04    7.58e+04\n",
      "Dept_96[T.1]  1.728e+04   1375.945     12.561      0.000    1.46e+04       2e+04\n",
      "Dept_97[T.1]  1.789e+04   1375.445     13.009      0.000    1.52e+04    2.06e+04\n",
      "Dept_98[T.1]  7592.4804   1396.739      5.436      0.000    4854.889    1.03e+04\n",
      "==============================================================================\n",
      "Omnibus:                    71167.635   Durbin-Watson:                   0.888\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          8893935.562\n",
      "Skew:                           2.695   Prob(JB):                         0.00\n",
      "Kurtosis:                      49.450   Cond. No.                         202.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     21.34\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):           3.86e-06\n",
      "Time:                        17:40:04   Log-Likelihood:            -1.1282e+06\n",
      "No. Observations:               97615   AIC:                         2.256e+06\n",
      "Df Residuals:                   97613   BIC:                         2.256e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept          1.716e+04     83.997    204.293      0.000     1.7e+04    1.73e+04\n",
      "IsHoliday[T.True]  1461.1823    316.324      4.619      0.000     841.191    2081.173\n",
      "==============================================================================\n",
      "Omnibus:                    72027.065   Durbin-Watson:                   1.139\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2083239.187\n",
      "Skew:                           3.262   Prob(JB):                         0.00\n",
      "Kurtosis:                      24.671   Cond. No.                         3.93\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.049\n",
      "Model:                            OLS   Adj. R-squared:                  0.049\n",
      "Method:                 Least Squares   F-statistic:                     5080.\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:04   Log-Likelihood:            -1.1257e+06\n",
      "No. Observations:               97615   AIC:                         2.251e+06\n",
      "Df Residuals:                   97613   BIC:                         2.251e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept     1.14e+04    113.995    100.033      0.000    1.12e+04    1.16e+04\n",
      "Type_A[T.1]  1.126e+04    158.052     71.272      0.000     1.1e+04    1.16e+04\n",
      "==============================================================================\n",
      "Omnibus:                    73335.994   Durbin-Watson:                   1.198\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2451559.407\n",
      "Skew:                           3.297   Prob(JB):                         0.00\n",
      "Kurtosis:                      26.649   Cond. No.                         2.67\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "stores= ['Store_1', 'Store_2', 'Store_3', 'Store_4', 'Store_5', 'Store_6', 'Store_7', 'Store_8', 'Store_9']\n",
    "dept = df.columns[17:95].astype(list)\n",
    "isholiday = ['IsHoliday']\n",
    "typecol = ['Type_A']\n",
    "\n",
    "collist = [stores, dept, isholiday, typecol]\n",
    "\n",
    "results = [['ind', 'rsquared', 'intercept', 'slope', 'pval']]\n",
    "\n",
    "for i, col in enumerate(collist):\n",
    "    combine = '+'.join(col)\n",
    "    f = \"Weekly_Sales~\" + combine\n",
    "    model = smf.ols(f, df).fit()\n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Sales   R-squared:                       0.128\n",
      "Model:                            OLS   Adj. R-squared:                  0.128\n",
      "Method:                 Least Squares   F-statistic:                     1591.\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:06   Log-Likelihood:            -1.9258e+05\n",
      "No. Observations:               97615   AIC:                         3.852e+05\n",
      "Df Residuals:                   97605   BIC:                         3.853e+05\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        9.2319      0.017    537.401      0.000       9.198       9.266\n",
      "Store_1[T.1]    -0.1932      0.024     -7.946      0.000      -0.241      -0.146\n",
      "Store_2[T.1]     0.1073      0.024      4.411      0.000       0.060       0.155\n",
      "Store_3[T.1]    -1.5577      0.025    -62.032      0.000      -1.607      -1.508\n",
      "Store_4[T.1]     0.1612      0.024      6.638      0.000       0.114       0.209\n",
      "Store_5[T.1]    -1.6343      0.025    -64.988      0.000      -1.684      -1.585\n",
      "Store_6[T.1]     0.0029      0.024      0.120      0.904      -0.045       0.051\n",
      "Store_7[T.1]    -1.2038      0.025    -48.898      0.000      -1.252      -1.156\n",
      "Store_8[T.1]    -0.5704      0.025    -23.257      0.000      -0.618      -0.522\n",
      "Store_9[T.1]    -1.0649      0.025    -42.165      0.000      -1.114      -1.015\n",
      "==============================================================================\n",
      "Omnibus:                    28899.366   Durbin-Watson:                   1.536\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           101987.299\n",
      "Skew:                          -1.476   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.045   Cond. No.                         10.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Sales   R-squared:                       0.624\n",
      "Model:                            OLS   Adj. R-squared:                  0.624\n",
      "Method:                 Least Squares   F-statistic:                     2074.\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:06   Log-Likelihood:            -1.5153e+05\n",
      "No. Observations:               97615   AIC:                         3.032e+05\n",
      "Df Residuals:                   97536   BIC:                         3.040e+05\n",
      "Df Model:                          78                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        3.5250      0.082     42.947      0.000       3.364       3.686\n",
      "Dept_1[T.1]      6.1872      0.087     70.738      0.000       6.016       6.359\n",
      "Dept_10[T.1]     6.5483      0.087     74.867      0.000       6.377       6.720\n",
      "Dept_11[T.1]     6.2272      0.087     71.195      0.000       6.056       6.399\n",
      "Dept_12[T.1]     5.1626      0.087     59.024      0.000       4.991       5.334\n",
      "Dept_13[T.1]     6.7177      0.087     76.803      0.000       6.546       6.889\n",
      "Dept_14[T.1]     5.9002      0.087     67.457      0.000       5.729       6.072\n",
      "Dept_16[T.1]     5.9452      0.087     67.971      0.000       5.774       6.117\n",
      "Dept_17[T.1]     5.4518      0.087     62.330      0.000       5.280       5.623\n",
      "Dept_18[T.1]     3.2716      0.089     36.700      0.000       3.097       3.446\n",
      "Dept_19[T.1]     3.6106      0.088     40.925      0.000       3.438       3.784\n",
      "Dept_2[T.1]      7.0202      0.087     80.261      0.000       6.849       7.192\n",
      "Dept_20[T.1]     4.8027      0.087     54.909      0.000       4.631       4.974\n",
      "Dept_21[T.1]     4.8653      0.087     55.625      0.000       4.694       5.037\n",
      "Dept_22[T.1]     5.4612      0.087     62.438      0.000       5.290       5.633\n",
      "Dept_23[T.1]     6.3335      0.087     72.411      0.000       6.162       6.505\n",
      "Dept_24[T.1]     4.8686      0.087     55.663      0.000       4.697       5.040\n",
      "Dept_25[T.1]     5.4723      0.087     62.565      0.000       5.301       5.644\n",
      "Dept_26[T.1]     5.1058      0.087     58.374      0.000       4.934       5.277\n",
      "Dept_27[T.1]     3.4421      0.087     39.353      0.000       3.271       3.613\n",
      "Dept_28[T.1]     2.4321      0.087     27.806      0.000       2.261       2.604\n",
      "Dept_29[T.1]     4.6629      0.087     53.311      0.000       4.491       4.834\n",
      "Dept_3[T.1]      5.6884      0.087     65.035      0.000       5.517       5.860\n",
      "Dept_30[T.1]     4.3979      0.087     50.281      0.000       4.226       4.569\n",
      "Dept_31[T.1]     3.9783      0.087     45.483      0.000       3.807       4.150\n",
      "Dept_32[T.1]     5.2895      0.087     60.472      0.000       5.118       5.461\n",
      "Dept_33[T.1]     4.9206      0.087     56.257      0.000       4.749       5.092\n",
      "Dept_34[T.1]     5.7016      0.087     65.186      0.000       5.530       5.873\n",
      "Dept_35[T.1]     4.1091      0.087     46.977      0.000       3.938       4.281\n",
      "Dept_36[T.1]     3.4955      0.087     39.956      0.000       3.324       3.667\n",
      "Dept_37[T.1]     4.6055      0.091     50.675      0.000       4.427       4.784\n",
      "Dept_38[T.1]     7.6361      0.087     87.303      0.000       7.465       7.808\n",
      "Dept_39[T.1]    -3.1953      0.518     -6.171      0.000      -4.210      -2.180\n",
      "Dept_4[T.1]      6.5681      0.087     75.093      0.000       6.397       6.740\n",
      "Dept_40[T.1]     7.1694      0.087     81.967      0.000       6.998       7.341\n",
      "Dept_41[T.1]     3.5359      0.087     40.425      0.000       3.364       3.707\n",
      "Dept_42[T.1]     5.2128      0.087     59.598      0.000       5.041       5.384\n",
      "Dept_44[T.1]     4.7871      0.087     54.730      0.000       4.616       4.958\n",
      "Dept_45[T.1]    -0.6790      0.096     -7.066      0.000      -0.867      -0.491\n",
      "Dept_46[T.1]     6.2029      0.087     70.918      0.000       6.031       6.374\n",
      "Dept_47[T.1]     0.6717      0.140      4.804      0.000       0.398       0.946\n",
      "Dept_48[T.1]     3.5379      0.091     38.834      0.000       3.359       3.716\n",
      "Dept_49[T.1]     4.2582      0.089     47.864      0.000       4.084       4.433\n",
      "Dept_5[T.1]      6.4041      0.087     73.218      0.000       6.233       6.576\n",
      "Dept_50[T.1]     4.8240      0.126     38.286      0.000       4.577       5.071\n",
      "Dept_51[T.1]    -1.4362      0.115    -12.497      0.000      -1.661      -1.211\n",
      "Dept_52[T.1]     4.0841      0.087     46.693      0.000       3.913       4.256\n",
      "Dept_54[T.1]     0.5819      0.088      6.586      0.000       0.409       0.755\n",
      "Dept_55[T.1]     5.6058      0.087     64.091      0.000       5.434       5.777\n",
      "Dept_56[T.1]     3.9199      0.087     44.810      0.000       3.748       4.091\n",
      "Dept_58[T.1]     4.4686      0.089     50.075      0.000       4.294       4.644\n",
      "Dept_59[T.1]     2.0382      0.088     23.157      0.000       1.866       2.211\n",
      "Dept_6[T.1]      4.7478      0.087     54.277      0.000       4.576       4.919\n",
      "Dept_60[T.1]     1.9082      0.088     21.688      0.000       1.736       2.081\n",
      "Dept_67[T.1]     5.1331      0.087     58.687      0.000       4.962       5.305\n",
      "Dept_7[T.1]      6.3196      0.087     72.252      0.000       6.148       6.491\n",
      "Dept_71[T.1]     4.3701      0.087     49.963      0.000       4.199       4.542\n",
      "Dept_72[T.1]     7.1710      0.087     81.986      0.000       7.000       7.342\n",
      "Dept_74[T.1]     5.7770      0.087     66.048      0.000       5.606       5.948\n",
      "Dept_77[T.1]     2.3249      0.239      9.738      0.000       1.857       2.793\n",
      "Dept_78[T.1]    -1.4447      0.191     -7.568      0.000      -1.819      -1.071\n",
      "Dept_79[T.1]     6.2467      0.087     71.418      0.000       6.075       6.418\n",
      "Dept_8[T.1]      6.7632      0.087     77.324      0.000       6.592       6.935\n",
      "Dept_80[T.1]     4.7921      0.089     53.555      0.000       4.617       4.967\n",
      "Dept_81[T.1]     5.5694      0.087     63.674      0.000       5.398       5.741\n",
      "Dept_82[T.1]     5.9775      0.087     68.341      0.000       5.806       6.149\n",
      "Dept_83[T.1]     4.2251      0.090     47.107      0.000       4.049       4.401\n",
      "Dept_85[T.1]     4.0244      0.087     46.011      0.000       3.853       4.196\n",
      "Dept_87[T.1]     6.0459      0.087     69.123      0.000       5.875       6.217\n",
      "Dept_9[T.1]      6.4500      0.087     73.742      0.000       6.279       6.621\n",
      "Dept_90[T.1]     6.2765      0.087     71.758      0.000       6.105       6.448\n",
      "Dept_91[T.1]     5.7453      0.087     65.685      0.000       5.574       5.917\n",
      "Dept_92[T.1]     7.1416      0.087     81.649      0.000       6.970       7.313\n",
      "Dept_93[T.1]     6.2598      0.090     69.815      0.000       6.084       6.436\n",
      "Dept_94[T.1]     5.0519      0.089     56.819      0.000       4.878       5.226\n",
      "Dept_95[T.1]     7.4049      0.087     84.660      0.000       7.234       7.576\n",
      "Dept_96[T.1]     5.6446      0.088     64.051      0.000       5.472       5.817\n",
      "Dept_97[T.1]     5.4253      0.088     61.585      0.000       5.253       5.598\n",
      "Dept_98[T.1]     4.2413      0.089     47.411      0.000       4.066       4.417\n",
      "==============================================================================\n",
      "Omnibus:                    33292.658   Durbin-Watson:                   0.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           249099.253\n",
      "Skew:                          -1.444   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.274   Cond. No.                         202.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Sales   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     9.748\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):            0.00180\n",
      "Time:                        17:40:06   Log-Likelihood:            -1.9925e+05\n",
      "No. Observations:               97615   AIC:                         3.985e+05\n",
      "Df Residuals:                   97613   BIC:                         3.985e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             8.6665      0.006   1401.125      0.000       8.654       8.679\n",
      "IsHoliday[T.True]     0.0727      0.023      3.122      0.002       0.027       0.118\n",
      "==============================================================================\n",
      "Omnibus:                    21883.886   Durbin-Watson:                   1.340\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            56621.948\n",
      "Skew:                          -1.220   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.822   Cond. No.                         3.93\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Sales   R-squared:                       0.068\n",
      "Model:                            OLS   Adj. R-squared:                  0.068\n",
      "Method:                 Least Squares   F-statistic:                     7074.\n",
      "Date:                Thu, 20 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:06   Log-Likelihood:            -1.9584e+05\n",
      "No. Observations:               97615   AIC:                         3.917e+05\n",
      "Df Residuals:                   97613   BIC:                         3.917e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       8.1673      0.008    982.410      0.000       8.151       8.184\n",
      "Type_A[T.1]     0.9695      0.012     84.106      0.000       0.947       0.992\n",
      "==============================================================================\n",
      "Omnibus:                    24208.178   Durbin-Watson:                   1.437\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            73067.927\n",
      "Skew:                          -1.285   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.371   Cond. No.                         2.67\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "stores= ['Store_1', 'Store_2', 'Store_3', 'Store_4', 'Store_5', 'Store_6', 'Store_7', 'Store_8', 'Store_9']\n",
    "dept = df.columns[17:95].astype(list)\n",
    "isholiday = ['IsHoliday']\n",
    "typecol = ['Type_A']\n",
    "\n",
    "collist = [stores, dept, isholiday, typecol]\n",
    "\n",
    "results = [['ind', 'rsquared', 'intercept', 'slope', 'pval']]\n",
    "\n",
    "for i, col in enumerate(collist):\n",
    "    combine = '+'.join(col)\n",
    "    f = \"Log_Sales~\" + combine\n",
    "    model = smf.ols(f, df).fit()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's drop a few columns in our data set based on our findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's stick with our `walmart_log` data, as it seemed like it was generally resulting in higher R-squared values.\n",
    "- Let's drop continuous variables which resulted in single linear models with a R-squared value <0.01 for the `walmart_log models`.\n",
    "- Let's make sure to drop 1 column for each categorical variable we end up using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Temperature', 'Fuel_Price', 'Unemployment', 'Store_10', 'Type_B', 'IsHoliday', 'Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.columns[:91]]\n",
    "df2 = df2.join(df.Log_Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Store_1</th>\n",
       "      <th>Store_2</th>\n",
       "      <th>Store_3</th>\n",
       "      <th>Store_4</th>\n",
       "      <th>Store_5</th>\n",
       "      <th>Store_6</th>\n",
       "      <th>Store_7</th>\n",
       "      <th>Store_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept_92</th>\n",
       "      <th>Dept_93</th>\n",
       "      <th>Dept_94</th>\n",
       "      <th>Dept_95</th>\n",
       "      <th>Dept_96</th>\n",
       "      <th>Dept_97</th>\n",
       "      <th>Dept_98</th>\n",
       "      <th>Dept_99</th>\n",
       "      <th>Type_A</th>\n",
       "      <th>Log_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.123607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.831811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.528075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.595485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.380634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Size      CPI Store_1 Store_2 Store_3 Store_4 Store_5 Store_6 Store_7  \\\n",
       "0  0.283436  0.40349       1       0       0       0       0       0       0   \n",
       "1  0.283436  0.40349       1       0       0       0       0       0       0   \n",
       "2  0.283436  0.40349       1       0       0       0       0       0       0   \n",
       "3  0.283436  0.40349       1       0       0       0       0       0       0   \n",
       "4  0.283436  0.40349       1       0       0       0       0       0       0   \n",
       "\n",
       "  Store_8    ...     Dept_92 Dept_93 Dept_94 Dept_95 Dept_96 Dept_97 Dept_98  \\\n",
       "0       0    ...           0       0       0       0       0       0       0   \n",
       "1       0    ...           0       0       0       0       0       0       0   \n",
       "2       0    ...           0       0       0       0       0       0       0   \n",
       "3       0    ...           0       0       0       0       0       0       0   \n",
       "4       0    ...           0       0       0       0       0       0       0   \n",
       "\n",
       "  Dept_99 Type_A  Log_Sales  \n",
       "0       0      1  10.123607  \n",
       "1       0      1  10.831811  \n",
       "2       0      1   9.528075  \n",
       "3       0      1  10.595485  \n",
       "4       0      1  10.380634  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here on out, use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a matrix X and y containing the predictors and target for our model. Let's use Scikit-Learn's RFE function, documentation again [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(columns='Log_Sales')\n",
    "y = df2.Log_Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a for loop using `RFE` where we look at the 5, 15, 25,... up until 85 best features to be selected according to the feature ranking algorithm. Store the R-squared and the adjusted-R-squareds for all these models in a list. What do you see? No need to perform a train-test-split for now- that will be next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10678957626950347\n",
      "0.1059561098199534\n",
      "0.23150643218719247\n",
      "0.2307893406839474\n",
      "0.3291277287136435\n",
      "0.3285017289321862\n",
      "0.4068264586459333\n",
      "0.4062729605761116\n",
      "0.4627371312643156\n",
      "0.46223580418193555\n",
      "0.5152878503752147\n",
      "0.5148355590632591\n",
      "0.5702871349562342\n",
      "0.5698861642034991\n",
      "0.623492107026028\n",
      "0.6231407825357986\n",
      "0.71612653025721\n",
      "0.7158616441713985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "\n",
    "rsquared = []\n",
    "adjrsquared = []\n",
    "nrange = range(5, 86, 10)\n",
    "\n",
    "for n in nrange:\n",
    "    selectn = RFE(linreg, n_features_to_select=n)\n",
    "    selectn = selectn.fit(X, y)\n",
    "    columnstoselect = X.columns[selectn.support_]\n",
    "    linreg.fit(X[columnstoselect], y)\n",
    "    r_squared = linreg.score(X[columnstoselect], y)\n",
    "    print(r_squared)\n",
    "    rsquared.append(r_squared)\n",
    "    adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "    print(adjusted_r_squared)\n",
    "    adjrsquared.append(adjusted_r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00083347, 0.00071709, 0.000626  , 0.0005535 , 0.00050133,\n",
       "       0.00045229, 0.00040097, 0.00035132, 0.00026489])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif = np.array(rsquared) - np.array(adjrsquared)\n",
    "dif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between $R^2$ and adjusted $R^2$ is negligible, and seems to continue to be going up as we include more features. Remember though that we're likely overfitting when including 85 features. In order to identify this, let's rerun a similar experiment, but using a train test split!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including a train-test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a similar for loop to what we did before. Except, this time\n",
    "- Use a train test split of 20-80\n",
    "- Instead of looking at $R^2$ and $R^2_{adj}$, look at the MSE for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "msetrain = []\n",
    "msetest = []\n",
    "nrange = range(5, 86, 10)\n",
    "\n",
    "for n in nrange:\n",
    "    selectn = RFE(linreg, n_features_to_select=n)\n",
    "    selectn = selectn.fit(X_train, y_train)\n",
    "    columnstoselect = X_train.columns[selectn.support_]\n",
    "    linreg.fit(X_train[columnstoselect], y_train)\n",
    "    yhat_train = linreg.predict(X_train[columnstoselect])\n",
    "    squareerror = (np.array(yhat_train) - np.array(y_train))**2\n",
    "    mse = squareerror.mean()\n",
    "    msetrain.append(mse)\n",
    "    yhat_test = linreg.predict(X_test[columnstoselect])\n",
    "    squareerror = (np.array(yhat_test) - np.array(y_test))**2\n",
    "    mse = squareerror.mean()\n",
    "    msetest.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.2054667812594895,\n",
       " 2.2562154359708564,\n",
       " 1.734958817747669,\n",
       " 1.4281423515621405,\n",
       " 1.2334120858366564,\n",
       " 1.1243951382589419,\n",
       " 1.0537114637599132,\n",
       " 1.0108122801137653,\n",
       " 0.9936093581910821]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.1828020281125866,\n",
       " 2.212061324411113,\n",
       " 1.6817821163990763,\n",
       " 1.3627738598533623,\n",
       " 1.1869321352164703,\n",
       " 1.0813305542971072,\n",
       " 1.0123933642479648,\n",
       " 0.9719428986857697,\n",
       " 0.9549796107717171]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msetest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that both MSE keeps improving when we add variables. It seems like a bigger model improves our performance, and the test and train performance don't really diverge. It is important to note however that is not an unusual result. The performance measures used typically will show this type of behavior. In order to really be able to balance the curse of dimensionality (which will become more important in machine learning), we need other information criteria such as AIC and BIC. You'll learn about them later! Now, let's perform cross-validation on our model with 85 predictors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold cross validation with the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 10-fold cross-validation and store the (negative) MSEs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.76654024, -0.69664019, -1.44835722, -0.70074499, -1.30540411,\n",
       "       -0.54245975, -1.1061533 , -0.59732938, -0.99564528, -3.67992343])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "selectn = RFE(linreg, n_features_to_select=85)\n",
    "selectn = selectn.fit(X, np.ravel(y))\n",
    "columnstoselect = X.columns[selectn.support_]\n",
    "\n",
    "cv10 = cross_val_score(linreg, X[columnstoselect], y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "cv10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running our 10-fold cross-validation highlights some issues for sure! Have a look at your list of 10 MSEs. Where most MSEs are manageable, some are very high. The cure of dimensionality is already pretty clear here. The issue is that we have many (dummy) categorical variables that result in columns with many zeroes and few ones. This means that for some folds, there is a risk of ending up with columns that almost exclusively contain 0's for prediction, which might cause weird results. Looking at this, a model with less predictors might make sense again. This is where we conclude for now. It's up to you now to explore other model options! Additionally, it is encouraged to try some of the \"level up\" exercises below. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level up - Optional\n",
    "\n",
    "\n",
    "- You could argue that **throwing out negative sales figures is problematic**, because these are probably the types of observations a stakeholder would be very interested in knowing. Repeat your analysis, but now, instead of removing the rows with negative sales, replace their sales with a slightly positive value (eg. 1), so they have an existing and finite value. Does the result change?\n",
    "\n",
    "- Go back and log-transform `CPI` and `Size` before standardizing it (we did this a few lessons ago). Look at the histogram and see if there is an improvement.\n",
    "- You might have noticed we ignored `binned_markdown` throughout. Add it in the model and see how it changes the results!\n",
    "\n",
    "- Try other feature selection methods such as stepwise selection and forward selection seen in section 11.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you made it to the end of the last section in this module. Now it's time for a big project on multiple linear regression!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
